# ğŸ“Š Which Headline Works Better?  
*A Sentiment-Based A/B Testing Project with Real API Data*  
**By Toluwalase Taiwo**  
ğŸ“… June 14, 2025

---

## ğŸ§  Project Summary

Ever wondered why some headlines grab more attention than others? In this project, I explored how **sentiment (positive vs. negative)** in news headlines affects user engagement. Using real-time articles from **The Guardian News API**, I analyzed the emotional tone of headlines and simulated reader behavior through **clicks and shares**.

---

## ğŸ¯ Objective

To test whether **positive** or **negative** sentiment in headlines leads to higher user engagement â€” measured through simulated **clicks** and **shares**.

---

## ğŸ› ï¸ Tools & Libraries Used

- **Python**  
- `Requests` â€“ For fetching data from The Guardian API  
- `Pandas` â€“ Data cleaning & manipulation  
- `TextBlob` â€“ Sentiment analysis  
- `NumPy` â€“ Simulating clicks and shares  
- `Matplotlib` & `Seaborn` â€“ Data visualization  
- `SciPy` â€“ T-tests for statistical significance  
- `WordCloud` â€“ Visualizing language patterns  

---

## ğŸ“¥ Data Collection

- **Source:** The Guardian API  
- **Fields Extracted:**  
  - Headline  
  - Summary (`trailText`)  
  - Section/category  
  - Published date  
  - Full article text  

Data was saved as a `.csv` file for easy analysis.

---

## ğŸ§ª Sentiment Analysis + A/B Testing

1. Cleaned and preprocessed the text data.
2. Used **TextBlob** to calculate sentiment polarity.
3. Filtered out neutral headlines to keep the test focused.
4. Grouped articles into **Positive** and **Negative**.
5. Simulated engagement:
   - Negative: Higher clicks/shares (200â€“350 clicks, 150â€“300 shares)
   - Positive: Lower clicks/shares (50â€“150 clicks, 40â€“120 shares)
6. Ran a **T-test** to compare average engagement across sentiment groups.

---
## ğŸ“¸ Visuals & Exploratory Insights

### ğŸ¯ Sentiment Distribution  
This barplot shows the number of articles classified as positive vs. negative after filtering out neutral ones. It sets the stage for the A/B test.

<p align="center">
  <img src="visuals/sentiment_distribution.png" alt="Sentiment Distribution" width="600"/>
</p>

---

### ğŸ“Š Engagement Boxplot by Sentiment  
This boxplot compares simulated clicks and shares across sentiment groups. It highlights how negative headlines tend to get more consistent and higher engagement.

<p align="center">
  <img src="visuals/boxplot_engagement.png" alt="Boxplot Engagement" width="600"/>
</p>

---

### ğŸ“ˆ Barplot â€“ Engagement Metrics  
A simple barplot showing average clicks and shares for each sentiment group. It gives a quick view of performance based on emotional tone.

<p align="center">
  <img src="visuals/barplot_engagement.png" alt="Barplot Engagement" width="600"/>
</p>

---

### â˜ï¸ WordCloud â€“ Combined  
A word cloud that visually represents the most common words across all headlines and summaries. Words appearing more frequently are displayed larger.

<p align="center">
  <img src="visuals/wordcloud.png" alt="WordCloud" width="600"/>
</p>

---

## ğŸ“ˆ Results

- **Negative headlines outperformed** positive ones in both clicks and shares.
- **T-test results** showed a **statistically significant difference** in engagement between sentiment groups (p < 0.0001).
- **Outlier Injection**: Added extreme values to demonstrate how a few viral articles can skew average metrics.

---

## ğŸ’¡ Insights & Takeaways

- Emotionally intense headlines (especially negative ones) draw more engagement.
- **Balancing tone** is important: while negative headlines pull readers in, too much negativity can affect brand perception.
- Simulating engagement helped mimic real-world dynamics, even without actual user data.

---

## ğŸ“ File Structure
```
which-headline-works-better/
â”œâ”€â”€ data/
â”‚ â””â”€â”€ guardian_articles.csv
â”œâ”€â”€ notebook/
â”‚ â””â”€â”€ headline_ab_test.ipynb
â”œâ”€â”€ visuals/
â”‚ â”œâ”€â”€ wordcloud_positive.png
â”‚ â”œâ”€â”€ wordcloud_negative.png
â”‚ â”œâ”€â”€ boxplot_engagement.png
â”‚ â””â”€â”€ sentiment_barplot.png
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore
```
---

## ğŸ”— Notebook & Dataset

- ğŸ““ [View the full Jupyter Notebook here](notebook/headline_ab_test.ipynb)  
- ğŸ“‚ [Download cleaned dataset](#)
  
---

## ğŸ“„ Full Project Walkthrough

For the full walkthrough of this project, please check this document:  
ğŸ‘‰ [Google Docs â€“ Project Breakdown](https://docs.google.com/document/d/1O2-k9V-x3NsBSVQObb5yCaSarpv-GFOIim_MpM6Ahk4/edit?usp=sharing)

It contains:

- âœ… Step-by-step breakdown of the analysis  
- ğŸ“Š Visualizations and interpretations  
- ğŸ’¡ Key insights and recommendations

---

## ğŸš€ How to Reproduce

1. Clone the repo  
2. Set up your environment:  
   ```bash
   pip install -r requirements.txt
3. Run the notebook step by step.

4. Optionally, register for an API key from [The Guardian Open Platform](https://open-platform.theguardian.com/) to fetch new data.
   
---

## ğŸª Personal Reflection

This was more than a technical exercise â€” it was a lesson in **how data reflects human behavior**. It helped me connect Python, NLP, and stats to real-world questions in media and communication.

---


